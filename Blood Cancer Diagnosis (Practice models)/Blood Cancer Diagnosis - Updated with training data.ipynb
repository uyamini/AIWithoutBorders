{"cells":[{"metadata":{},"cell_type":"markdown","source":"Aim:\nFinding a suitable model for classification of leukemic B-lymphoblast cells from normal B-lymphoid precursors from blood smear microscopic images. \n\nWe have used a CNN model and some pretrained models like ResNet50, VGG16, VGG19 and InceptionV3 in this process.\nAfter training the models for 15 epochs, the VGG19 model came up with the highest accuracy among all of them with about ~78% accuracy and VGG16 was the second highest with a little less accuracy than the former with about ~77%.\n\nThe reason behind VGG models getting so much higher accuracy in comparison to others is its architecture, the main key points of this architecture are as follows: \n\n*    Use of very small convolutional filters, e.g. 3×3 and 1×1 with a stride of one.\n*    Use of max pooling with a size of 2×2 and a stride of the same dimensions.\n*    The importance of stacking convolutional layers together before using a pooling layer to define a block.\n*    Dramatic repetition of the convolutional-pooling block pattern.\n*    Development of very deep (16 and 19 layer) models.\n\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nfrom glob import glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['blood-cancer-training-dataset', 'blood-cancer-test-dataset']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom glob import glob\n%matplotlib inline\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.metrics import confusion_matrix\n\nimport keras\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, DepthwiseConv2D\nfrom keras import backend as K\nimport itertools\nfrom keras import optimizers\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"os.listdir(\"../input\")","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"['blood-cancer-training-dataset', 'blood-cancer-test-dataset']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This cell can be used to access and use the TEST dataset available\n\n# data = pd.read_csv(\"../input/blood-cancer-test-dataset/c-nmc_test_prelim_phase_data/C-NMC_test_prelim_phase_data/C-NMC_test_prelim_phase_data_labels.csv\")\n# print(data.head())\n\n# baseadd = \"../input/blood-cancer-test-dataset/c-nmc_test_prelim_phase_data/C-NMC_test_prelim_phase_data/C-NMC_test_prelim_phase_data\"\n# image_path_dict = {os.path.basename(x): x for x in glob(os.path.join(baseadd, \"*.bmp\"))}\n# data[\"path\"] = (data[\"new_names\"]).map(image_path_dict.get)\n# data['image'] = data['path'].map(lambda x: np.asarray(Image.open(x).resize((224, 224))))\n# data[\"image\"].shape\n# print(data.head())\n\n# data[\"Patient_ID\"][0].split('_')\n# subject_id_dict = {data[\"Patient_ID\"][x]: data[\"Patient_ID\"][x].split(\"_\")[1] for x in range(len(data[\"Patient_ID\"]))}\n# image_id_dict = {data[\"Patient_ID\"][x]: data[\"Patient_ID\"][x].split(\"_\")[2] for x in range(len(data[\"Patient_ID\"]))}\n# cell_id_dict = {data[\"Patient_ID\"][x]: data[\"Patient_ID\"][x].split(\"_\")[3] for x in range(len(data[\"Patient_ID\"]))}\n\n# data[\"subject_id\"] = data[\"Patient_ID\"].map(subject_id_dict.get)\n# data[\"image_id\"] = data[\"Patient_ID\"].map(image_id_dict.get)\n# data[\"cell_no\"] = data[\"Patient_ID\"].map(cell_id_dict.get)\n# # data[\"cell_state\"] = data[\"Patient_ID\"].map(cell_type_id_dict.get)\n# subject_filter_dict = {data[\"subject_id\"][x]: data[\"subject_id\"][x][1:] if \"H\" in data[\"subject_id\"][x] \n#                        else data[\"subject_id\"][x] for x in range(len(data[\"Patient_ID\"]))}\n# data[\"subject_id\"] = data[\"subject_id\"].map(subject_filter_dict.get)\n# print(data.sample(5))\n\n# plt.imshow(data[\"image\"][0])\n# plt.axis(\"off\")\n\n# data[\"labels\"].value_counts().plot(kind = \"bar\")\n# print(data[\"labels\"].value_counts())\n\n# plt.scatter(data['subject_id'], data['cell_no'])\n# plt.title(\"Subject Id distribution\")\n\n# data['subject_id'].value_counts().plot(kind = 'bar')\n# plt.title(\"Subject Id dis\")","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"baseadd_tr = \"../input/blood-cancer-training-dataset/c-nmc_training_data(1)/C-NMC_training_data\"\nimage_path_dict_tr = {os.path.basename(x).split(\".\")[0]: x for x in glob(os.path.join(baseadd_tr, \"*\", \"*\", \"*.bmp\"))}","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_tr = pd.DataFrame()\npassword = [os.path.basename(x).split(\".\")[0] for x in glob(os.path.join(baseadd_tr, \"*\", \"*\", \"*.bmp\"))]\ndata_tr[\"Patient_ID\"] = password\ndata_tr.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"          Patient_ID\n0   UID_H14_26_1_hem\n1   UID_H10_63_1_hem\n2   UID_H14_30_6_hem\n3  UID_H10_190_3_hem\n4  UID_H14_19_15_hem","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>UID_H14_26_1_hem</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>UID_H10_63_1_hem</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>UID_H14_30_6_hem</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>UID_H10_190_3_hem</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>UID_H14_19_15_hem</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_tr[\"path\"] = data_tr[\"Patient_ID\"].map(image_path_dict_tr.get)\ndata_tr['image'] = data_tr['path'].map(lambda x: np.asarray(Image.open(x).resize((150, 150))))\ndata_tr.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"          Patient_ID                        ...                                                                      image\n0   UID_H14_26_1_hem                        ...                          [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n1   UID_H10_63_1_hem                        ...                          [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n2   UID_H14_30_6_hem                        ...                          [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n3  UID_H10_190_3_hem                        ...                          [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n4  UID_H14_19_15_hem                        ...                          [[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...\n\n[5 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_ID</th>\n      <th>path</th>\n      <th>image</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>UID_H14_26_1_hem</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>UID_H10_63_1_hem</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>UID_H14_30_6_hem</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>UID_H10_190_3_hem</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>UID_H14_19_15_hem</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_tr[\"image\"].shape","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"(10661,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_tr[\"Patient_ID\"][0].split('_')\nsubject_id_dict_tr = {data_tr[\"Patient_ID\"][x]: data_tr[\"Patient_ID\"][x].split(\"_\")[1] for x in range(len(data_tr[\"Patient_ID\"]))}\nimage_id_dict_tr = {data_tr[\"Patient_ID\"][x]: data_tr[\"Patient_ID\"][x].split(\"_\")[2] for x in range(len(data_tr[\"Patient_ID\"]))}\ncell_id_dict_tr = {data_tr[\"Patient_ID\"][x]: data_tr[\"Patient_ID\"][x].split(\"_\")[3] for x in range(len(data_tr[\"Patient_ID\"]))}\ndata_tr[\"subject_id\"] = data_tr[\"Patient_ID\"].map(subject_id_dict_tr.get)\ndata_tr[\"image_id\"] = data_tr[\"Patient_ID\"].map(image_id_dict_tr.get)\ndata_tr[\"cell_no\"] = data_tr[\"Patient_ID\"].map(cell_id_dict_tr.get)\n# data[\"cell_state\"] = data[\"Patient_ID\"].map(cell_type_id_dict.get)\nsubject_filter_dict_tr = {data_tr[\"subject_id\"][x]: data_tr[\"subject_id\"][x][1:] if \"H\" in data_tr[\"subject_id\"][x] \n                       else data_tr[\"subject_id\"][x] for x in range(len(data_tr[\"Patient_ID\"]))}\ndata_tr[\"subject_id\"] = data_tr[\"subject_id\"].map(subject_filter_dict_tr.get)\ndata_tr.sample(5)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"            Patient_ID   ...   cell_no\n6405   UID_78_35_2_all   ...         2\n2929   UID_30_27_9_all   ...         9\n6002   UID_27_30_3_all   ...         3\n7830  UID_H17_29_4_hem   ...         4\n6548   UID_75_34_1_all   ...         1\n\n[5 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_ID</th>\n      <th>path</th>\n      <th>image</th>\n      <th>subject_id</th>\n      <th>image_id</th>\n      <th>cell_no</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6405</th>\n      <td>UID_78_35_2_all</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>78</td>\n      <td>35</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2929</th>\n      <td>UID_30_27_9_all</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>30</td>\n      <td>27</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>6002</th>\n      <td>UID_27_30_3_all</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>27</td>\n      <td>30</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>7830</th>\n      <td>UID_H17_29_4_hem</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>17</td>\n      <td>29</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>6548</th>\n      <td>UID_75_34_1_all</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>75</td>\n      <td>34</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0 means normal cell, while 1 means a cancer diagnosed cell\nlabel_dict = {password[x] : password[x].split(\"_\")[-1] for x in range(len(password))}\ndata_tr[\"labels\"] = data_tr[\"Patient_ID\"].map(label_dict.get)\ndata_tr[\"labels\"] = data_tr[\"labels\"].apply(lambda x: 1 if x == 'all' else 0)\ndata_tr.sample(5)","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"             Patient_ID  ...   labels\n1049   UID_H14_8_13_hem  ...        0\n4804    UID_24_28_1_all  ...        1\n10400   UID_11_28_3_all  ...        1\n2525     UID_44_2_2_all  ...        1\n5482     UID_31_9_3_all  ...        1\n\n[5 rows x 7 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Patient_ID</th>\n      <th>path</th>\n      <th>image</th>\n      <th>subject_id</th>\n      <th>image_id</th>\n      <th>cell_no</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1049</th>\n      <td>UID_H14_8_13_hem</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>14</td>\n      <td>8</td>\n      <td>13</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4804</th>\n      <td>UID_24_28_1_all</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>24</td>\n      <td>28</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10400</th>\n      <td>UID_11_28_3_all</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>11</td>\n      <td>28</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2525</th>\n      <td>UID_44_2_2_all</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>44</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5482</th>\n      <td>UID_31_9_3_all</td>\n      <td>../input/blood-cancer-training-dataset/c-nmc_t...</td>\n      <td>[[[0, 0, 0], [0, 0, 0], [0, 0, 0], [0, 0, 0], ...</td>\n      <td>31</td>\n      <td>9</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"plt.imshow(data_tr[\"image\"][0])\nplt.axis(\"off\")","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"(-0.5, 149.5, 149.5, -0.5)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_tr[\"labels\"].value_counts().plot(kind = \"bar\")\ndata_tr[\"labels\"].value_counts()","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"1    7272\n0    3389\nName: labels, dtype: int64"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAEJFJREFUeJzt3W+MpWV5x/HvT1Zsq627yEDo7rZL40bFFyKdAI1J00q7LNi4vJAE05QJ2WT7AhtNmlTsm1WQBN8US1JJNrJ2MVaktIaNJdLJKmmahj+DUBSQ7ojKTpayo7NgLVELXn0x98phmdk5szs7R7i/n2TyPPf1XM8590Mm/Ob5c86mqpAk9ed1o56AJGk0DABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSp9aMegLHcvrpp9emTZtGPQ1JelV58MEHf1BVY0v1/VIHwKZNm5iamhr1NCTpVSXJ94fp8xKQJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVO/1B8Ee7XYdM2/jHoKrynfu+F9o56C1AXPACSpUwaAJHXKAJCkThkAktSpJQMgyduSPDzw86MkH0lyWpLJJPvbcl3rT5KbkkwneSTJeQOvNdH69yeZOJkHJkk6tiUDoKqeqKpzq+pc4HeB54EvA9cA+6pqM7CvjQEuATa3nx3AzQBJTgN2AhcA5wM7j4SGJGn1LfcS0EXAd6rq+8A2YE+r7wEua+vbgFtr3r3A2iRnARcDk1U1V1WHgUlg6wkfgSTpuCw3AK4AvtjWz6yqpwHa8oxWXw8cGNhnptUWq79Mkh1JppJMzc7OLnN6kqRhDR0ASU4F3g/841KtC9TqGPWXF6p2VdV4VY2PjS35L5pJko7Tcs4ALgG+UVXPtPEz7dIObXmo1WeAjQP7bQAOHqMuSRqB5QTAB3np8g/AXuDIkzwTwJ0D9Svb00AXAs+1S0R3A1uSrGs3f7e0miRpBIb6LqAkvwb8MfDnA+UbgNuTbAeeAi5v9buAS4Fp5p8YugqgquaSXAc80Pquraq5Ez4CSdJxGSoAqup54C1H1X7I/FNBR/cWcPUir7Mb2L38aUqSVpqfBJakThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6NVQAJFmb5I4k307yeJLfS3Jakskk+9tyXetNkpuSTCd5JMl5A68z0fr3J5k4WQclSVrasGcAfwt8tareDrwLeBy4BthXVZuBfW0McAmwuf3sAG4GSHIasBO4ADgf2HkkNCRJq2/JAEjyG8DvA7cAVNXPqupZYBuwp7XtAS5r69uAW2vevcDaJGcBFwOTVTVXVYeBSWDrih6NJGlow5wB/A4wC3wuyUNJPpvkjcCZVfU0QFue0frXAwcG9p9ptcXqkqQRGCYA1gDnATdX1buB/+Wlyz0LyQK1Okb95TsnO5JMJZmanZ0dYnqSpOMxTADMADNVdV8b38F8IDzTLu3QlocG+jcO7L8BOHiM+stU1a6qGq+q8bGxseUciyRpGZYMgKr6b+BAkre10kXAY8Be4MiTPBPAnW19L3BlexroQuC5donobmBLknXt5u+WVpMkjcCaIfv+AvhCklOBJ4GrmA+P25NsB54CLm+9dwGXAtPA862XqppLch3wQOu7tqrmVuQoJEnLNlQAVNXDwPgCmy5aoLeAqxd5nd3A7uVMUJJ0cvhJYEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdWqoAEjyvSTfTPJwkqlWOy3JZJL9bbmu1ZPkpiTTSR5Jct7A60y0/v1JJk7OIUmShrGcM4A/rKpzq2q8ja8B9lXVZmBfGwNcAmxuPzuAm2E+MICdwAXA+cDOI6EhSVp9J3IJaBuwp63vAS4bqN9a8+4F1iY5C7gYmKyquao6DEwCW0/g/SVJJ2DYACjgX5M8mGRHq51ZVU8DtOUZrb4eODCw70yrLVZ/mSQ7kkwlmZqdnR3+SCRJy7JmyL73VNXBJGcAk0m+fYzeLFCrY9RfXqjaBewCGB8ff8V2SdLKGOoMoKoOtuUh4MvMX8N/pl3aoS0PtfYZYOPA7huAg8eoS5JGYMkASPLGJL9+ZB3YAnwL2AsceZJnArizre8FrmxPA10IPNcuEd0NbEmyrt383dJqkqQRGOYS0JnAl5Mc6f+HqvpqkgeA25NsB54CLm/9dwGXAtPA88BVAFU1l+Q64IHWd21Vza3YkUiSlmXJAKiqJ4F3LVD/IXDRAvUCrl7ktXYDu5c/TUnSSvOTwJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnhg6AJKckeSjJV9r47CT3Jdmf5EtJTm31N7TxdNu+aeA1PtbqTyS5eKUPRpI0vOWcAXwYeHxg/CngxqraDBwGtrf6duBwVb0VuLH1keQc4ArgncBW4DNJTjmx6UuSjtdQAZBkA/A+4LNtHOC9wB2tZQ9wWVvf1sa07Re1/m3AbVX106r6LjANnL8SByFJWr5hzwA+DfwV8PM2fgvwbFW90MYzwPq2vh44ANC2P9f6f1FfYB9J0ipbMgCS/AlwqKoeHCwv0FpLbDvWPoPvtyPJVJKp2dnZpaYnSTpOw5wBvAd4f5LvAbcxf+nn08DaJGtazwbgYFufATYCtO1vBuYG6wvs8wtVtauqxqtqfGxsbNkHJEkazpIBUFUfq6oNVbWJ+Zu4X6uqPwW+DnygtU0Ad7b1vW1M2/61qqpWv6I9JXQ2sBm4f8WORJK0LGuWblnUR4HbknwSeAi4pdVvAT6fZJr5v/yvAKiqR5PcDjwGvABcXVUvnsD7S5JOwLICoKruAe5p60+ywFM8VfUT4PJF9r8euH65k5QkrTw/CSxJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkTp3It4FKejX4+JtHPYPXjo8/N+oZrCjPACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6tSSAZDkV5Lcn+Q/kzya5BOtfnaS+5LsT/KlJKe2+hvaeLpt3zTwWh9r9SeSXHyyDkqStLRhzgB+Cry3qt4FnAtsTXIh8CngxqraDBwGtrf+7cDhqnorcGPrI8k5wBXAO4GtwGeSnLKSByNJGt6SAVDzftyGr28/BbwXuKPV9wCXtfVtbUzbflGStPptVfXTqvouMA2cvyJHIUlatqHuASQ5JcnDwCFgEvgO8GxVvdBaZoD1bX09cACgbX8OeMtgfYF9Bt9rR5KpJFOzs7PLPyJJ0lCGCoCqerGqzgU2MP9X+zsWamvLLLJtsfrR77WrqsaranxsbGyY6UmSjsOyngKqqmeBe4ALgbVJjnyZ3AbgYFufATYCtO1vBuYG6wvsI0laZcM8BTSWZG1b/1Xgj4DHga8DH2htE8CdbX1vG9O2f62qqtWvaE8JnQ1sBu5fqQORJC3PMF8HfRawpz2x8zrg9qr6SpLHgNuSfBJ4CLil9d8CfD7JNPN/+V8BUFWPJrkdeAx4Abi6ql5c2cORJA1ryQCoqkeAdy9Qf5IFnuKpqp8Aly/yWtcD1y9/mpKkleYngSWpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROLRkASTYm+XqSx5M8muTDrX5akskk+9tyXasnyU1JppM8kuS8gdeaaP37k0ycvMOSJC1lmDOAF4C/rKp3ABcCVyc5B7gG2FdVm4F9bQxwCbC5/ewAbob5wAB2Ahcw/4/J7zwSGpKk1bdkAFTV01X1jbb+P8DjwHpgG7Cnte0BLmvr24Bba969wNokZwEXA5NVNVdVh4FJYOuKHo0kaWjLugeQZBPwbuA+4MyqehrmQwI4o7WtBw4M7DbTaovVj36PHUmmkkzNzs4uZ3qSpGUYOgCSvAn4J+AjVfWjY7UuUKtj1F9eqNpVVeNVNT42Njbs9CRJyzRUACR5PfP/8/9CVf1zKz/TLu3QlodafQbYOLD7BuDgMeqSpBEY5imgALcAj1fV3wxs2gsceZJnArhzoH5lexroQuC5donobmBLknXt5u+WVpMkjcCaIXreA/wZ8M0kD7faXwM3ALcn2Q48BVzett0FXApMA88DVwFU1VyS64AHWt+1VTW3IkchSVq2JQOgqv6dha/fA1y0QH8BVy/yWruB3cuZoCTp5PCTwJLUKQNAkjplAEhSpwwASeqUASBJnTIAJKlTBoAkdcoAkKROGQCS1CkDQJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6tSSAZBkd5JDSb41UDstyWSS/W25rtWT5KYk00keSXLewD4TrX9/komTcziSpGENcwbw98DWo2rXAPuqajOwr40BLgE2t58dwM0wHxjATuAC4Hxg55HQkCSNxpIBUFX/BswdVd4G7Gnre4DLBuq31rx7gbVJzgIuBiaraq6qDgOTvDJUJEmr6HjvAZxZVU8DtOUZrb4eODDQN9Nqi9VfIcmOJFNJpmZnZ49zepKkpaz0TeAsUKtj1F9ZrNpVVeNVNT42Nraik5MkveR4A+CZdmmHtjzU6jPAxoG+DcDBY9QlSSNyvAGwFzjyJM8EcOdA/cr2NNCFwHPtEtHdwJYk69rN3y2tJkkakTVLNST5IvAHwOlJZph/mucG4PYk24GngMtb+13ApcA08DxwFUBVzSW5Dnig9V1bVUffWJYkraIlA6CqPrjIposW6C3g6kVeZzewe1mzkySdNH4SWJI6ZQBIUqcMAEnqlAEgSZ0yACSpUwaAJHXKAJCkThkAktQpA0CSOmUASFKnDABJ6pQBIEmdMgAkqVMGgCR1ygCQpE4ZAJLUKQNAkjplAEhSpwwASerUqgdAkq1JnkgyneSa1X5/SdK8VQ2AJKcAfwdcApwDfDDJOas5B0nSvNU+AzgfmK6qJ6vqZ8BtwLZVnoMkCVizyu+3HjgwMJ4BLhhsSLID2NGGP07yxCrNrQenAz8Y9SSWkk+NegYagVfF7yafyKhnMKzfHqZptQNgof969bJB1S5g1+pMpy9JpqpqfNTzkI7m7+ZorPYloBlg48B4A3BwlecgSWL1A+ABYHOSs5OcClwB7F3lOUiSWOVLQFX1QpIPAXcDpwC7q+rR1ZxD57y0pl9W/m6OQKpq6S5J0muOnwSWpE4ZAJLUKQNAkjq12p8DkCSSvJ35bwFYz/xngQ4Ce6vq8ZFOrDOeAUhaVUk+yvzXwAS4n/nHwwN80S+IXF0+BdShJFdV1edGPQ/1Kcl/Ae+sqv87qn4q8GhVbR7NzPrjGUCfPjHqCahrPwd+c4H6WW2bVon3AF6jkjyy2CbgzNWci3SUjwD7kuznpS+H/C3grcCHRjarDnkJ6DUqyTPAxcDhozcB/1FVC/0FJq2KJK9j/uvh1zP/OzkDPFBVL450Yp3xDOC16yvAm6rq4aM3JLln9acjvaSqfg7cO+p59M4zAEnqlDeBJalTBoAkdcoAkKROGQCS1Kn/B4U9eWsyNdYdAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_tr['subject_id'].value_counts().plot(kind = 'bar')\nplt.title(\"Subject Id distribution\")\nplt.figure(figsize = (60, 60))","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<Figure size 4320x4320 with 0 Axes>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 4320x4320 with 0 Axes>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data_tr.drop([\"labels\"], axis = 1)\ny = data_tr[\"labels\"]","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n\ny_train.value_counts().plot(kind = \"bar\")\ny_test.value_counts().plot(kind = \"bar\")\n\nprint(\"%age of label value 0 in training dataset\", \n      y_train.value_counts()[0]/(y_train.value_counts()[0]+y_train.value_counts()[1]))\nprint(\"%age of label value 0 in test dataset\", \n      y_test.value_counts()[0]/(y_test.value_counts()[0]+y_test.value_counts()[1]))","execution_count":15,"outputs":[{"output_type":"stream","text":"%age of label value 0 in training dataset 0.3187148217636023\n%age of label value 0 in test dataset 0.3145804031879981\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalization\nx_train = np.asarray(x_train['image'].tolist())\nx_test = np.asarray(x_test['image'].tolist())\n\nx_train_mean = np.mean(x_train)\nx_test_mean = np.mean(x_test)\n\nx_train_std = np.std(x_train)\nx_test_std = np.std(x_test)\n\nx_train = (x_train - x_train_mean)/x_train_std\nx_test = (x_test - x_test_mean)/x_test_std\n\n# Label Encoding\ny_train = to_categorical(y_train, num_classes = 2)\ny_test = to_categorical(y_test, num_classes = 2)\n\n# Reshape images in 3 dimensions\nx_train = x_train.reshape(x_train.shape[0], *(150, 150, 3))\nx_test = x_test.reshape(x_test.shape[0], *(150, 150, 3))\nx_train.shape","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"(8528, 150, 150, 3)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## Defining models to train on our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (150, 150, 3)\nnum_classes = 2\n# Set learning rate annealer\nlearning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc', patience = 3, verbose = 1, \n                                           factor = 0.5, min_lr = 0.00001)\n\n# Data Augmentation\ndatagen = ImageDataGenerator(featurewise_center = False, samplewise_center = True,\n                            featurewise_std_normalization = False, samplewise_std_normalization = True, \n                            zca_whitening = False, rotation_range = 0, zoom_range = 0.3, \n                            width_shift_range = 0.2, height_shift_range = 0.2, horizontal_flip = False, \n                            vertical_flip = False, rescale = 1./255)\ndatagen.fit(x_train)\n\n# Define the optimizer\n# optimizer = Adam(lr = .001, beta_1 = .9, beta_2 = .999, epsilon = None, decay = .0, amsgrad = False)\n# Fit the model\n# \n# epochs = 20\n# batch_size = 80","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining and fitting Capsule network"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom __future__ import print_function\nfrom keras import backend as K\nfrom keras.layers import Layer\nfrom keras import activations\nfrom keras import utils\n# from keras.datasets import cifar10\nfrom keras.models import Model\nfrom keras.layers import *\nfrom keras.preprocessing.image import ImageDataGenerator\n\n\n# the squashing function.\n# we use 0.5 instead of 1 in hinton's paper.\n# if 1, the norm of vector will be zoomed out.\n# if 0.5, the norm will be zoomed in while original norm is less than 0.5\n# and be zoomed out while original norm is greater than 0.5.\ndef squash(x, axis=-1):\n    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n    return scale * x\n\n\n# define our own softmax function instead of K.softmax\n# because K.softmax can not specify axis.\ndef softmax(x, axis=-1):\n    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n    return ex / K.sum(ex, axis=axis, keepdims=True)\n\n\n# define the margin loss like hinge loss\ndef margin_loss(y_true, y_pred):\n    lamb, margin = 0.5, 0.1\n    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)\n\n\nclass Capsule(Layer):\n    \"\"\"A Capsule Implement with Pure Keras\n    There are two vesions of Capsule.\n    One is like dense layer (for the fixed-shape input),\n    and the other is like time distributed dense (for various length input).\n\n    The input shape of Capsule must be (batch_size,\n                                        input_num_capsule,\n                                        input_dim_capsule\n                                       )\n    and the output shape is (batch_size,\n                             num_capsule,\n                             dim_capsule\n                            )\n\n    Capsule Implement is from https://github.com/bojone/Capsule/\n    Capsule Paper: https://arxiv.org/abs/1710.09829\n    \"\"\"\n\n    def __init__(self,\n                 num_capsule,\n                 dim_capsule,\n                 routings=3,\n                 share_weights=True,\n                 activation='squash',\n                 **kwargs):\n        super(Capsule, self).__init__(**kwargs)\n        self.num_capsule = num_capsule\n        self.dim_capsule = dim_capsule\n        self.routings = routings\n        self.share_weights = share_weights\n        if activation == 'squash':\n            self.activation = squash\n        else:\n            self.activation = activations.get(activation)\n\n    def build(self, input_shape):\n        input_dim_capsule = input_shape[-1]\n        if self.share_weights:\n            self.kernel = self.add_weight(\n                name='capsule_kernel',\n                shape=(1, input_dim_capsule,\n                       self.num_capsule * self.dim_capsule),\n                initializer='glorot_uniform',\n                trainable=True)\n        else:\n            input_num_capsule = input_shape[-2]\n            self.kernel = self.add_weight(\n                name='capsule_kernel',\n                shape=(input_num_capsule, input_dim_capsule,\n                       self.num_capsule * self.dim_capsule),\n                initializer='glorot_uniform',\n                trainable=True)\n\n    def call(self, inputs):\n        \"\"\"Following the routing algorithm from Hinton's paper,\n        but replace b = b + <u,v> with b = <u,v>.\n\n        This change can improve the feature representation of Capsule.\n\n        However, you can replace\n            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n        with\n            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n        to realize a standard routing.\n        \"\"\"\n\n        if self.share_weights:\n            hat_inputs = K.conv1d(inputs, self.kernel)\n        else:\n            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n\n        batch_size = K.shape(inputs)[0]\n        input_num_capsule = K.shape(inputs)[1]\n        hat_inputs = K.reshape(hat_inputs,\n                               (batch_size, input_num_capsule,\n                                self.num_capsule, self.dim_capsule))\n        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n\n        b = K.zeros_like(hat_inputs[:, :, :, 0])\n        for i in range(self.routings):\n            c = softmax(b, 1)\n            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n            if i < self.routings - 1:\n                b = K.batch_dot(o, hat_inputs, [2, 3])\n                if K.backend() == 'keras':\n                    o = K.sum(o, axis=1)\n\n        return o\n\n    def compute_output_shape(self, input_shape):\n        return (None, self.num_capsule, self.dim_capsule)\n\n\nbatch_size = 128\nnum_classes = 2\nepochs = 20\n# # (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# # x_train = x_train.astype('float32')\n# # x_test = x_test.astype('float32')\n# # x_train /= 255\n# # x_test /= 255\n# # y_train = utils.to_categorical(y_train, num_classes)\n# # y_test = utils.to_categorical(y_test, num_classes)\n\n# A common Conv2D model\ninput_image = Input(shape=(None, None, 3))\nx = Conv2D(64, (3, 3), activation='relu')(input_image)\nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = AveragePooling2D((2, 2))(x)\nx = Conv2D(128, (3, 3), activation='relu')(x)\nx = Conv2D(128, (3, 3), activation='relu')(x)\nx = AveragePooling2D((2, 2))(x)\n\n\n\"\"\"now we reshape it as (batch_size, input_num_capsule, input_dim_capsule)\nthen connect a Capsule layer.\n\nthe output of final model is the lengths of 10 Capsule, whose dim=16.\n\nthe length of Capsule is the proba,\nso the problem becomes a 10 two-classification problem.\n\"\"\"\n\nx = Reshape((-1, 128))(x)\ncapsule = Capsule(2, 16, 3, True)(x)\ncapsule = Dense(1, activation = 'sigmoid')(capsule)\noutput = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\nmodel = Model(inputs=input_image, outputs=output)\n\n# we use a margin loss\nmodel.compile(loss=margin_loss, optimizer= optimizers.Adam(lr = 0.001), metrics=['mae', 'acc'])\nmodel.summary()\n\n# we can compare the performance with or without data augmentation\ndata_augmentation = False\n\nif not data_augmentation:\n    print('Not using data augmentation.')\n    model.fit_generator(\n        datagen.flow(x_train, y_train, batch_size=batch_size),\n        epochs=epochs,\n        validation_data=(x_test, y_test),\n        steps_per_epoch = x_train.shape[0] // batch_size)\nelse:\n    print('Using real-time data augmentation.')\n    # This will do preprocessing and realtime data augmentation:\n    datagen1 = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by dataset std\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n        rotation_range=0,  # randomly rotate images in 0 to 180 degrees\n        width_shift_range=0.1,  # randomly shift images horizontally\n        height_shift_range=0.1,  # randomly shift images vertically\n        shear_range=0.,  # set range for random shear\n        zoom_range=0.,  # set range for random zoom\n        channel_shift_range=0.,  # set range for random channel shifts\n        # set mode for filling points outside the input boundaries\n        fill_mode='nearest',\n        cval=0.,  # value used for fill_mode = \"constant\"\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False,  # randomly flip images\n        # set rescaling factor (applied before any other transformation)\n        rescale=None,\n        # set function that will be applied on each input\n        preprocessing_function=None,\n        # image data format, either \"channels_first\" or \"channels_last\"\n        data_format=None,\n        # fraction of images reserved for validation (strictly between 0 and 1)\n        validation_split=0.0)\n\n    # Compute quantities required for feature-wise normalization\n    # (std, mean, and principal components if ZCA whitening is applied).\n    datagen.fit(x_train)\n\n    # Fit the model on the batches generated by datagen.flow().\n    model.fit_generator(\n        datagen1.flow(x_train, y_train, batch_size=batch_size),\n        epochs=epochs,\n        validation_data=(x_test, y_test),\n        steps_per_epoch = x_train.shape[0] // batch_size,\n        workers=4)\n\n","execution_count":18,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, None, None, 3)     0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, None, None, 64)    1792      \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, None, None, 64)    36928     \n_________________________________________________________________\naverage_pooling2d_1 (Average (None, None, None, 64)    0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, None, None, 128)   73856     \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, None, None, 128)   147584    \n_________________________________________________________________\naverage_pooling2d_2 (Average (None, None, None, 128)   0         \n_________________________________________________________________\nreshape_1 (Reshape)          (None, None, 128)         0         \n_________________________________________________________________\ncapsule_1 (Capsule)          (None, 2, 16)             4096      \n_________________________________________________________________\ndense_1 (Dense)              (None, 2, 1)              17        \n_________________________________________________________________\nlambda_1 (Lambda)            (None, 2)                 0         \n=================================================================\nTotal params: 264,273\nTrainable params: 264,273\nNon-trainable params: 0\n_________________________________________________________________\nNot using data augmentation.\nEpoch 1/20\n66/66 [==============================] - 47s 719ms/step - loss: 0.1770 - mean_absolute_error: 0.4307 - acc: 0.6767 - val_loss: 0.2103 - val_mean_absolute_error: 0.4850 - val_acc: 0.6854\nEpoch 2/20\n66/66 [==============================] - 43s 648ms/step - loss: 0.1747 - mean_absolute_error: 0.4280 - acc: 0.6809 - val_loss: 0.1690 - val_mean_absolute_error: 0.4387 - val_acc: 0.6854\nEpoch 3/20\n66/66 [==============================] - 43s 645ms/step - loss: 0.1694 - mean_absolute_error: 0.4198 - acc: 0.6838 - val_loss: 0.1677 - val_mean_absolute_error: 0.4166 - val_acc: 0.6854\nEpoch 4/20\n66/66 [==============================] - 42s 642ms/step - loss: 0.1684 - mean_absolute_error: 0.4179 - acc: 0.7069 - val_loss: 0.1644 - val_mean_absolute_error: 0.4309 - val_acc: 0.6854\nEpoch 5/20\n66/66 [==============================] - 42s 633ms/step - loss: 0.1573 - mean_absolute_error: 0.4049 - acc: 0.7526 - val_loss: 0.1943 - val_mean_absolute_error: 0.4184 - val_acc: 0.6770\nEpoch 6/20\n66/66 [==============================] - 42s 639ms/step - loss: 0.1497 - mean_absolute_error: 0.3873 - acc: 0.7652 - val_loss: 0.2076 - val_mean_absolute_error: 0.4290 - val_acc: 0.6517\nEpoch 7/20\n66/66 [==============================] - 42s 638ms/step - loss: 0.1489 - mean_absolute_error: 0.3836 - acc: 0.7684 - val_loss: 0.2030 - val_mean_absolute_error: 0.4205 - val_acc: 0.6770\nEpoch 8/20\n66/66 [==============================] - 42s 637ms/step - loss: 0.1424 - mean_absolute_error: 0.3762 - acc: 0.7748 - val_loss: 0.2144 - val_mean_absolute_error: 0.4098 - val_acc: 0.6770\nEpoch 9/20\n66/66 [==============================] - 42s 640ms/step - loss: 0.1389 - mean_absolute_error: 0.3668 - acc: 0.7844 - val_loss: 0.2046 - val_mean_absolute_error: 0.4038 - val_acc: 0.6746\nEpoch 10/20\n66/66 [==============================] - 42s 638ms/step - loss: 0.1374 - mean_absolute_error: 0.3633 - acc: 0.7877 - val_loss: 0.2193 - val_mean_absolute_error: 0.3981 - val_acc: 0.6845\nEpoch 11/20\n66/66 [==============================] - 42s 638ms/step - loss: 0.1339 - mean_absolute_error: 0.3560 - acc: 0.7944 - val_loss: 0.2255 - val_mean_absolute_error: 0.3897 - val_acc: 0.6868\nEpoch 12/20\n66/66 [==============================] - 42s 643ms/step - loss: 0.1275 - mean_absolute_error: 0.3441 - acc: 0.8061 - val_loss: 0.2191 - val_mean_absolute_error: 0.3878 - val_acc: 0.6859\nEpoch 13/20\n66/66 [==============================] - 42s 641ms/step - loss: 0.1280 - mean_absolute_error: 0.3452 - acc: 0.8024 - val_loss: 0.2350 - val_mean_absolute_error: 0.3831 - val_acc: 0.6859\nEpoch 14/20\n66/66 [==============================] - 42s 642ms/step - loss: 0.1176 - mean_absolute_error: 0.3260 - acc: 0.8229 - val_loss: 0.2305 - val_mean_absolute_error: 0.3830 - val_acc: 0.6859\nEpoch 15/20\n66/66 [==============================] - 42s 642ms/step - loss: 0.1205 - mean_absolute_error: 0.3315 - acc: 0.8171 - val_loss: 0.2281 - val_mean_absolute_error: 0.3848 - val_acc: 0.6859\nEpoch 16/20\n66/66 [==============================] - 43s 646ms/step - loss: 0.1133 - mean_absolute_error: 0.3190 - acc: 0.8285 - val_loss: 0.2405 - val_mean_absolute_error: 0.3784 - val_acc: 0.6864\nEpoch 17/20\n66/66 [==============================] - 42s 642ms/step - loss: 0.1148 - mean_absolute_error: 0.3196 - acc: 0.8263 - val_loss: 0.2163 - val_mean_absolute_error: 0.3889 - val_acc: 0.6873\nEpoch 18/20\n66/66 [==============================] - 42s 642ms/step - loss: 0.1134 - mean_absolute_error: 0.3171 - acc: 0.8259 - val_loss: 0.2464 - val_mean_absolute_error: 0.3730 - val_acc: 0.6859\nEpoch 19/20\n66/66 [==============================] - 42s 639ms/step - loss: 0.1035 - mean_absolute_error: 0.2983 - acc: 0.8471 - val_loss: 0.2317 - val_mean_absolute_error: 0.3779 - val_acc: 0.6864\nEpoch 20/20\n66/66 [==============================] - 42s 643ms/step - loss: 0.1031 - mean_absolute_error: 0.2994 - acc: 0.8472 - val_loss: 0.2442 - val_mean_absolute_error: 0.3770 - val_acc: 0.6868\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Fitting our pretrained models"},{"metadata":{},"cell_type":"markdown","source":"Densenet"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.densenet import DenseNet121\nmodel_densenet = Sequential()\nmodel_densenet.add(DenseNet121(include_top=False, pooling= 'max', weights='imagenet'))\nmodel_densenet.add(Dense(num_classes, activation = \"softmax\"))\n\nmodel_densenet.trainable = False\n\nmodel_densenet.compile(optimizer = \"Adam\", loss = \"categorical_crossentropy\", \n                       metrics = ['mae', 'accuracy'])\n\nprint(\"*\"*40 + \"Densenet model\" + \"*\"*40)\nhistory = model_densenet.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                           verbose = 1,\n                           epochs = epochs,\n                           steps_per_epoch= x_train.shape[0] // batch_size, \n                            callbacks = [learning_rate_reduction],\n                           validation_data = (x_test, y_test))","execution_count":19,"outputs":[{"output_type":"stream","text":"****************************************Densenet model****************************************\nEpoch 1/20\n66/66 [==============================] - 49s 743ms/step - loss: 2.7870 - mean_absolute_error: 0.6421 - acc: 0.3454 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 2/20\n66/66 [==============================] - 39s 593ms/step - loss: 2.7423 - mean_absolute_error: 0.6397 - acc: 0.3477 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 3/20\n66/66 [==============================] - 41s 624ms/step - loss: 2.7877 - mean_absolute_error: 0.6456 - acc: 0.3399 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 4/20\n66/66 [==============================] - 41s 622ms/step - loss: 2.7458 - mean_absolute_error: 0.6373 - acc: 0.3485 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\n\nEpoch 00004: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\nEpoch 5/20\n66/66 [==============================] - 39s 598ms/step - loss: 2.7607 - mean_absolute_error: 0.6429 - acc: 0.3411 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 6/20\n66/66 [==============================] - 41s 616ms/step - loss: 2.8062 - mean_absolute_error: 0.6456 - acc: 0.3438 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 7/20\n66/66 [==============================] - 41s 615ms/step - loss: 2.7852 - mean_absolute_error: 0.6420 - acc: 0.3432 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\n\nEpoch 00007: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\nEpoch 8/20\n66/66 [==============================] - 41s 620ms/step - loss: 2.7719 - mean_absolute_error: 0.6408 - acc: 0.3435 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 9/20\n66/66 [==============================] - 41s 622ms/step - loss: 2.7625 - mean_absolute_error: 0.6384 - acc: 0.3500 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 10/20\n66/66 [==============================] - 41s 620ms/step - loss: 2.7641 - mean_absolute_error: 0.6383 - acc: 0.3491 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\n\nEpoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\nEpoch 11/20\n66/66 [==============================] - 41s 622ms/step - loss: 2.7696 - mean_absolute_error: 0.6420 - acc: 0.3451 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 12/20\n66/66 [==============================] - 41s 623ms/step - loss: 2.7458 - mean_absolute_error: 0.6357 - acc: 0.3526 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 13/20\n66/66 [==============================] - 41s 625ms/step - loss: 2.7569 - mean_absolute_error: 0.6414 - acc: 0.3432 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\n\nEpoch 00013: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\nEpoch 14/20\n66/66 [==============================] - 41s 627ms/step - loss: 2.7980 - mean_absolute_error: 0.6425 - acc: 0.3455 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 15/20\n66/66 [==============================] - 41s 618ms/step - loss: 2.7533 - mean_absolute_error: 0.6390 - acc: 0.3513 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 16/20\n66/66 [==============================] - 41s 625ms/step - loss: 2.7332 - mean_absolute_error: 0.6341 - acc: 0.3520 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\n\nEpoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\nEpoch 17/20\n66/66 [==============================] - 41s 619ms/step - loss: 2.7603 - mean_absolute_error: 0.6387 - acc: 0.3514 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 18/20\n66/66 [==============================] - 41s 622ms/step - loss: 2.7706 - mean_absolute_error: 0.6406 - acc: 0.3445 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\nEpoch 19/20\n66/66 [==============================] - 41s 616ms/step - loss: 2.7615 - mean_absolute_error: 0.6419 - acc: 0.3427 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\n\nEpoch 00019: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\nEpoch 20/20\n66/66 [==============================] - 41s 619ms/step - loss: 2.7457 - mean_absolute_error: 0.6397 - acc: 0.3461 - val_loss: 1.6846 - val_mean_absolute_error: 0.5203 - val_acc: 0.4843\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\nfrom keras.applications import ResNet50, VGG16, VGG19, InceptionV3\n# Using pretrained models for VGG16, VGG19, resnet, InceptionV3\n# If you are using Kaggle kernel, do switch ON the Internet from Settings.\n\n# from keras.applications.nasnet import NASNetMobile\n# model_nasnet = Sequential()\n# model_nasnet.add(NASNetMobile(input_shape=None, include_top=False, \n#                              weights='imagenet', input_tensor=None, pooling='max', classes=1000))\n# model_nasnet.add(Dense(num_classes, activation = \"softmax\"))\n\n# from keras.applications.mobilenet_v2 import MobileNetV2\n# model_mobile = Sequential()\n# model_mobile.add(MobileNetV2(input_shape=None, alpha=1.0, \n#                         include_top=False, weights='imagenet', input_tensor=None, pooling='max'))\n# model_mobile.add(Dense(num_classes, activation = \"softmax\"))\n\n# model_resnet = Sequential()\n# model_resnet.add(ResNet50(include_top=False, pooling='max', weights= \"imagenet\"))\n# model_resnet.add(Dense(num_classes, activation='softmax'))\n\n# model_vgg16 = Sequential()\n# model_vgg16.add(VGG16(include_top= False, pooling = \"max\", weights = \"imagenet\"))\n# model_vgg16.add(Dense(num_classes, activation = \"softmax\"))\n\nmodel_vgg19 = Sequential()\nmodel_vgg19.add(VGG19(include_top= False, pooling = \"max\", weights = \"imagenet\"))\nmodel_vgg19.add(Dense(num_classes, activation = \"softmax\"))\n\n# model_inception = Sequential()\n# model_inception.add(InceptionV3(include_top= False, pooling = \"max\", weights = \"imagenet\"))\n# model_inception.add(Dense(num_classes, activation = \"softmax\"))\n\n# Say not to train first layer (ResNet) model. It is already trained\n# model_nasnet.layers[0].trainable = False\n# model_mobile.layers[0].trainable = False\n# model_resnet.layers[0].trainable = False\n# model_vgg16.layers[0].trainable = False\nmodel_vgg19.layers[0].trainable = False\n# model_inception.layers[0].trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the pretrained models\n# model_nasnet.compile(optimizer= \"Adamax\", loss='categorical_crossentropy', metrics=['accuracy'])\n\n# model_mobile.compile(optimizer= \"Adamax\", loss='categorical_crossentropy', metrics=['accuracy'])\n\n# model_resnet.compile(optimizer= \"Adamax\", loss='categorical_crossentropy', metrics=['accuracy'])\n\n# model_vgg16.compile(optimizer = \"Adamax\", loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n\nmodel_vgg19.compile(optimizer = \"Adamax\", loss = \"categorical_crossentropy\", metrics = ['mae', 'accuracy'])\n\n# model_inception.compile(optimizer = 'Adamax', loss = \"categorical_crossentropy\", metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nrandom.seed(1234)\n# reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2,\n#                               patience=3, min_lr=0.001)\n# Fit the model\n# print(\"*\"*40 + \"Nasnet model\" + \"*\"*40)\n# history = model_nasnet.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n#                            verbose = 0,\n#                            epochs = epochs,\n#                            steps_per_epoch=x_train.shape[0] // batch_size,\n#                                      callbacks = [learning_rate_reduction],\n#                            validation_data = (x_test, y_test))\n\n# print(\"*\"*40 + \"Mobile model\" + \"*\"*40)\n# history = model_mobile.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n#                            verbose = 0,\n#                            epochs = epochs,\n#                            steps_per_epoch=x_train.shape[0] // batch_size,\n#                                      callbacks = [learning_rate_reduction],\n#                            validation_data = (x_test, y_test))\n\n# print(\"*\"*40 + \"ResNet50 model\" + \"*\"*40)\n# history = model_resnet.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n#                            verbose = 1,\n#                            epochs = epochs,\n#                            steps_per_epoch=x_train.shape[0] // batch_size,\n#                                      callbacks = [learning_rate_reduction],\n#                            validation_data = (x_test, y_test))\n# print(\"*\"*40 + \"VGG16 model\" + \"*\"*40)\n# history = model_vgg16.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n#                            verbose = 1,\n#                            epochs = epochs,\n#                            steps_per_epoch=x_train.shape[0] // batch_size, \n#                             callbacks = [learning_rate_reduction], \n#                             validation_data = (x_test, y_test))\n\nprint(\"*\"*40 + \"VGG19 model\" + \"*\"*40)\nhistory = model_vgg19.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n                           verbose = 1,\n                           epochs = epochs,\n                           steps_per_epoch= x_train.shape[0] // batch_size, \n                            callbacks = [learning_rate_reduction],\n                           validation_data = (x_test, y_test))\n\n# print(\"*\"*40 + \"inception model\" + \"*\"*40)\n# history = model_inception.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n#                            verbose = 1,\n#                            epochs = epochs,\n#                            steps_per_epoch=x_train.shape[0] // batch_size,\n#                             callbacks = [learning_rate_reduction], \n#                            validation_data = (x_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"| Model/Architecture | Type | Optimizer | Accuracy(in %) |\n| --- | --- | --- | --- |\n| CNN | Raw | Adam | ~65 ||\n| ResNet50 | Pre-Trained | sgd | ~64 |\n| VGG16 | Pre-Trained | sgd | ~77 |\n| VGG19 | Pre-Trained | sgd | ~79 |\n| Inception | Pre-Trained | sgd | ~64 |\n| VGG16 | Pre-Trained | Adam | ~81 |\n| VGG19 | Pre-Trained | Adam | ~83 |\n| VGG16 | Pre-Trained | Adamax | ~79 |\n| VGG19 | Pre-Trained | Adamax | ~78 |\n| VGG16 | Pre-Trained | Nadam | ~80 |\n| VGG19 | Pre-Trained | Nadam | ~79 |"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}